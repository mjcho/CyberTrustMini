geom_density(position = "stack") +
scale_fill_discrete(name = "Topic Categories") +
ggtitle("LDA Topic Modelling: phone")
phAll.lda <- LDA(phAll.dtm, control = list(seed = 240), k = 5)
(phAll.term <- terms(phAll.lda, k = 5))
(laAll.term <- terms(laAll.lda, k = 5))
phAll.lda <- LDA(phAll.dtm, control = list(seed = 300), k = 5)
(phAll.term <- terms(phAll.lda, k = 5))
laTopics <- topics(laAll.lda)
topics <- data.frame(hour = strptime(laAll.nonZero$captured, format = "%H:%M"), topic = laTopics)
ggplot(topics, aes(hour, ..count.., fill = laAll.term[laTopics])) +
geom_density(position = "stack") +
scale_fill_discrete(name = "Topic Categories") +
ggtitle("LDA Topic Modelling: laptop")
laAll.term <- apply(laAll.term, 2, paste, collapse = ", ")
laTopics <- topics(laAll.lda)
topics <- data.frame(hour = strptime(laAll.nonZero$captured, format = "%H:%M"), topic = laTopics)
ggplot(topics, aes(hour, ..count.., fill = laAll.term[laTopics])) +
geom_density(position = "stack") +
scale_fill_discrete(name = "Topic Categories") +
ggtitle("LDA Topic Modelling: laptop")
phAll.term
laAll.term
(phAll.term <- terms(phAll.lda, k = 5))
(laAll.term <- terms(laAll.lda, k = 5))
laAll.term[1, 1]
laAll.term[1, 1] <- "FIRST_NAME"
phAll.term <- apply(phAll.term, 2, paste, collapse = ", ")
laAll.term <- apply(laAll.term, 2, paste, collapse = ", ")
phTopics <- topics(phAll.lda)
topics <- data.frame(hour = strptime(phAll.nonZero$captured, format = "%H:%M"), topic = phTopics)
ggplot(topics, aes(hour, ..count.., fill = phAll.term[phTopics])) +
geom_density(position = "stack") +
scale_fill_discrete(name = "Topic Categories") +
ggtitle("LDA Topic Modelling: phone")
laTopics <- topics(laAll.lda)
topics <- data.frame(hour = strptime(laAll.nonZero$captured, format = "%H:%M"), topic = laTopics)
ggplot(topics, aes(hour, ..count.., fill = laAll.term[laTopics])) +
geom_density(position = "stack") +
scale_fill_discrete(name = "Topic Categories") +
ggtitle("LDA Topic Modelling: laptop")
phTopics <- topics(phAll.lda)
phTopicsDF <- data.frame(hour = strptime(phAll.nonZero$captured, format = "%H:%M"), topic = phTopics)
ggplot(phTopicsDF, aes(hour, ..count.., fill = phAll.term[phTopics])) +
geom_density(position = "stack") +
scale_fill_discrete(name = "Topic Categories") +
ggtitle("LDA Topic Modelling: phone")
laTopics <- topics(laAll.lda)
laTopicsDF <- data.frame(hour = strptime(laAll.nonZero$captured, format = "%H:%M"), topic = laTopics)
ggplot(laTopicsDF, aes(hour, ..count.., fill = laAll.term[laTopics])) +
geom_density(position = "stack") +
scale_fill_discrete(name = "Topic Categories") +
ggtitle("LDA Topic Modelling: laptop")
phAll.lda <- LDA(phAll.dtm, control = list(seed = 720), k = 5)
(phAll.term <- terms(phAll.lda, k = 5))
phAll.term <- apply(phAll.term, 2, paste, collapse = ", ")
phTopics <- topics(phAll.lda)
phTopicsDF <- data.frame(hour = strptime(phAll.nonZero$captured, format = "%H:%M"), topic = phTopics)
ggplot(phTopicsDF, aes(hour, ..count.., fill = phAll.term[phTopics])) +
geom_density(position = "stack") +
scale_fill_discrete(name = "Topic Categories") +
ggtitle("LDA Topic Modelling: phone")
save(phTopicsDF, laTopicsDF, file = "topisDF.rda")
library(slidify)
author("CyberTrust")
load("scoreList.rda")
getwd()
load("scoreList.rda")
statsList <- lapply(scoreList, function(x) {
x <- subset(x, category != "" & !is.na(category))
tab <- x %>%
group_by(category) %>%
summarise(n = n(),
avg = mean(meanScore),
sd = sd(meanScore)) %>%
mutate(se = sd / sqrt(n),
lowerCI = avg - qt(1 - .025, n - 1)*se,
upperCI = avg + qt(1 - .025, n - 1)*se)
tab
})
library(dplyr)
statsList <- lapply(scoreList, function(x) {
x <- subset(x, category != "" & !is.na(category))
tab <- x %>%
group_by(category) %>%
summarise(n = n(),
avg = mean(meanScore),
sd = sd(meanScore)) %>%
mutate(se = sd / sqrt(n),
lowerCI = avg - qt(1 - .025, n - 1)*se,
upperCI = avg + qt(1 - .025, n - 1)*se)
tab
})
save(statsList, "statsList.rda")
save(statsList, file = "statsList.rda")
ggplot(phTopicsDF, aes(hour, fill = phAll.term[phTopics])) +
geom_density(position = "stack") +
scale_fill_discrete(name = "Topic Categories") +
ggtitle("LDA Topic Modelling: phone")
ggplot(laTopicsDF, aes(hour, fill = laAll.term[laTopics])) +
geom_density(position = "stack") +
scale_fill_discrete(name = "Topic Categories") +
ggtitle("LDA Topic Modelling: laptop")
phTopicsDF
phTopicsDF <- data.frame(hour = strptime(phAll.nonZero$captured, format = "%H:%M"),
score = phAll.nonZero$meanScore,
topic = phTopics)
laTopicsDF <- data.frame(hour = strptime(laAll.nonZero$captured, format = "%H:%M"),
score = phAll.nonZero$meanScore,
topic = laTopics)
ggplot(phTopicsDF, aes(hour, fill = phAll.term[phTopics])) +
geom_density(position = "stack") +
scale_fill_discrete(name = "Topic Categories") +
ggtitle("LDA Topic Modelling: phone") +
geom_line(aes(score))
ggplot(phTopicsDF, aes(hour, fill = phAll.term[phTopics])) +
geom_density(position = "stack") +
scale_fill_discrete(name = "Topic Categories") +
ggtitle("LDA Topic Modelling: phone") +
geom_line(aes(hour, score))
ggplot(phTopicsDF, aes(hour, fill = phAll.term[phTopics])) +
geom_density(position = "stack") +
scale_fill_discrete(name = "Topic Categories") +
ggtitle("LDA Topic Modelling: phone")
ggplot(phTopicsDF, aes(hour, score))
ggplot(phTopicsDF, aes(hour, score)) +
geom_line()
ggplot(phTopicsDF, aes(hour, score)) +
geom_line() +
geom_smooth()
ggplot(phTopicsDF, aes(hour, score)) +
geom_smooth()
library(grid)
ph1 <- ggplot(phTopicsDF, aes(hour, fill = phAll.term[phTopics])) +
geom_density(position = "stack") +
scale_fill_discrete(name = "Topic Categories") +
ggtitle("LDA Topic Modelling: phone")
ph2 <- ggplot(phTopicsDF, aes(hour, score)) +
geom_smooth()
grid.newpage()
grid.draw(rbind(ggplotGrob(ph1), ggplotGrob(ph2)), size = "last")
grid.draw(rbind(ggplotGrob(ph1), ggplotGrob(ph2), size = "last"))
ph1 <- ggplot(phTopicsDF, aes(hour, fill = phAll.term[phTopics])) +
geom_density(position = "stack") +
scale_fill_discrete(name = "Topic Categories") +
ggtitle("LDA Topic Modelling: phone")
ph2 <- ggplot(phTopicsDF, aes(hour, score)) +
geom_smooth()
grid.newpage()
grid.draw(rbind(ggplotGrob(ph1), ggplotGrob(ph2), size = "last"))
grid.draw(combine(ph1, ph2, along = 2))
grid.draw(combine(ggplotGrob(ph1), ggplotGrob(ph2), along = 2))
library(gridExtra)
ph1 <- ggplot(phTopicsDF, aes(hour, fill = phAll.term[phTopics])) +
geom_density(position = "stack") +
scale_fill_discrete(name = "Topic Categories") +
ggtitle("LDA Topic Modelling: phone")
ph2 <- ggplot(phTopicsDF, aes(hour, score)) +
geom_smooth()
grid.newpage()
grid.draw(combine(ggplotGrob(ph1), ggplotGrob(ph2), along = 2))
grid.newpage()
colnames(ph1) <- paste0(seq_len(ncol(ph1)))
colnames(ph2) <- paste0(seq_len(ncol(ph2)))
grid.draw(combine(ggplotGrob(ph1), ggplotGrob(ph2), along = 2))
grid.arrange(ph1, ph2, ncol = 1)
save(phTopicsDF, laTopicsDF, file = "topicsDF.rda")
save(phTopicsDF, laTopicsDF, file = "topicsDF.rda")
grid.arrange(la1, la2, ncol = 1)
la1 <- ggplot(laTopicsDF, aes(hour, fill = laAll.term[laTopics])) +
geom_density(position = "stack") +
scale_fill_discrete(name = "Topic Categories") +
ggtitle("LDA Topic Modelling: laptop")
la2 <- ggplot(laTopicsDF, aes(hour, score)) +
geom_smooth()
grid.arrange(la1, la2, ncol = 1)
laTopics <- topics(laAll.lda)
laTopicsDF <- data.frame(hour = strptime(laAll.nonZero$captured, format = "%H:%M"),
score = phAll.nonZero$meanScore,
topic = laTopics)
la1 <- ggplot(laTopicsDF, aes(hour, fill = laAll.term[laTopics])) +
geom_density(position = "stack") +
scale_fill_discrete(name = "Topic Categories") +
ggtitle("LDA Topic Modelling: laptop")
la2 <- ggplot(laTopicsDF, aes(hour, score)) +
geom_smooth()
grid.arrange(la1, la2, ncol = 1)
laTopics <- topics(laAll.lda)
laTopicsDF <- data.frame(hour = strptime(laAll.nonZero$captured, format = "%H:%M"),
score = laAll.nonZero$meanScore,
topic = laTopics)
la1 <- ggplot(laTopicsDF, aes(hour, fill = laAll.term[laTopics])) +
geom_density(position = "stack") +
scale_fill_discrete(name = "Topic Categories") +
ggtitle("LDA Topic Modelling: laptop")
la2 <- ggplot(laTopicsDF, aes(hour, score)) +
geom_smooth()
grid.arrange(la1, la2, ncol = 1)
save(phTopicsDF, laTopicsDF, file = "topicsDF.rda")
save(phTopicsDF, laTopicsDF, file = "topicsDF.rda")
ph2 <- ggplot(phTopicsDF, aes(hour, score)) +
geom_smooth(span = 3)
grid.arrange(ph1, ph2, ncol = 1)
ph2 <- ggplot(phTopicsDF, aes(hour, score)) +
geom_smooth(span = 1)
grid.arrange(ph1, ph2, ncol = 1)
ph2 <- ggplot(phTopicsDF, aes(hour, score)) +
geom_smooth(span = 1)
grid.arrange(ph1, ph2, ncol = 0.1)
ph2 <- ggplot(phTopicsDF, aes(hour, score)) +
geom_smooth(span = 0.1)
grid.arrange(ph1, ph2, ncol = 1)
ph2 <- ggplot(phTopicsDF, aes(hour, score)) +
geom_smooth(method = "loess", span = 0.1)
grid.arrange(ph1, ph2, ncol = 1)
ph2 <- ggplot(phTopicsDF, aes(hour, score)) +
geom_smooth(method = "loess", span = 0.5)
grid.arrange(ph1, ph2, ncol = 1)
ph2 <- ggplot(phTopicsDF, aes(hour, score)) +
geom_smooth(method = "loess", span = 0.4)
grid.arrange(ph1, ph2, ncol = 1)
la2 <- ggplot(laTopicsDF, aes(hour, score)) +
geom_smooth(method = "loess", span = 0.4)
grid.arrange(la1, la2, ncol = 1)
la2 <- ggplot(laTopicsDF, aes(hour, score)) +
geom_smooth(method = "loess", span = 0.5)
grid.arrange(la1, la2, ncol = 1)
la2 <- ggplot(laTopicsDF, aes(hour, score)) +
geom_smooth()
grid.arrange(la1, la2, ncol = 1)
la2 <- ggplot(laTopicsDF, aes(hour, score)) +
geom_smooth(method = "loess", span = 0.5)
grid.arrange(la1, la2, ncol = 1)
la2 <- ggplot(laTopicsDF, aes(hour, score)) +
geom_smooth(method = "loess", span = 1)
grid.arrange(la1, la2, ncol = 1)
la2 <- ggplot(laTopicsDF, aes(hour, score)) +
geom_smooth(method = "loess", span = 0.4)
grid.arrange(la1, la2, ncol = 1)
save(phTopics, laTopics, phAll.term, laAll.term, file = "topicAndTerm.rda")
slidify("index.rmd")
publish(user = "mjcho", repo = "CyberTrustMini")
phAll.lda <- LDA(phAll.dtm, control = list(seed = 720), k = 3)
laAll.lda <- LDA(laAll.dtm, control = list(seed = 370), k = 3)
## Extract the first 5 terms of each topic
(phAll.term <- terms(phAll.lda, k = 3))
(laAll.term <- terms(laAll.lda, k = 3))
laAll.term[1, 1] <- "FIRST_NAME"
phAll.term <- apply(phAll.term, 2, paste, collapse = ", ")
laAll.term <- apply(laAll.term, 2, paste, collapse = ", ")
(phAll.term <- terms(phAll.lda, k = 5))
(laAll.term <- terms(laAll.lda, k = 5))
phAll.tdm
phAll.dtm
dim(dfPhone)
dim(dfLaptop)
laAll.dtm
install.packages("LDAvis")
topicmodels_json_ldavis <- function(fitted, corpus, doc_term){
## Required packages
library(topicmodels)
library(dplyr)
library(stringi)
library(tm)
library(LDAvis)
## Find required quantities
phi <- posterior(fitted)$terms %>% as.matrix
theta <- posterior(fitted)$topics %>% as.matrix
vocab <- colnames(phi)
doc_length <- vector()
for (i in 1:length(corpus)) {
temp <- paste(corpus[[i]]$content, collapse = ' ')
doc_length <- c(doc_length, stri_count(temp, regex = '\\S+'))
}
temp_frequency <- inspect(doc_term)
freq_matrix <- data.frame(ST = colnames(temp_frequency),
Freq = colSums(temp_frequency))
rm(temp_frequency)
## Convert to json
json_lda <- LDAvis::createJSON(phi = phi, theta = theta,
vocab = vocab,
doc.length = doc_length,
term.frequency = freq_matrix$Freq)
return(json_lda)
}
class(phAll)
phJSON <- topicmodels_json_ldavis(phAll.lda, phAll, phAll.dtm)
## Identify first 5 topics
phAll.lda <- LDA(phAll.dtm, control = list(seed = 720), k = 5)
laAll.lda <- LDA(laAll.dtm, control = list(seed = 370), k = 5)
## Extract the first 5 terms of each topic
(phAll.term <- terms(phAll.lda, k = 5))
(laAll.term <- terms(laAll.lda, k = 5))
laAll.term[1, 1] <- "FIRST_NAME"
phAll.term <- apply(phAll.term, 2, paste, collapse = ", ")
laAll.term <- apply(laAll.term, 2, paste, collapse = ", ")
## Plot change of topics over time
phAll.nonZero <- dfPhone[phAll.inds, ]
laAll.nonZero <- dfLaptop[laAll.inds, ]
phJSON <- topicmodels_json_ldavis(phAll.lda, phAll, phAll.dtm)
posterior(phAll.lda)$topics
dim(posterior(phAll.lda)$topics)
topicmodels_json_ldavis <- function(fitted, corpus, doc_term){
## Required packages
library(topicmodels)
library(dplyr)
library(stringi)
library(tm)
library(LDAvis)
## Find required quantities
phi <- posterior(fitted)$terms %>% as.matrix
theta <- posterior(fitted)$topics %>% as.matrix
vocab <- colnames(phi)
doc_length <- vector()
for (i in 1:length(corpus)) {
temp <- paste(corpus[[i]]$content, collapse = ' ')
doc_length <- c(doc_length, stri_count(temp, regex = '\\S+'))
}
print(doc_length)
temp_frequency <- inspect(doc_term)
freq_matrix <- data.frame(ST = colnames(temp_frequency),
Freq = colSums(temp_frequency))
rm(temp_frequency)
## Convert to json
json_lda <- LDAvis::createJSON(phi = phi, theta = theta,
vocab = vocab,
doc.length = doc_length,
term.frequency = freq_matrix$Freq)
return(json_lda)
}
phJSON <- topicmodels_json_ldavis(phAll.lda, phAll, phAll.dtm)
topicmodels_json_ldavis <- function(fitted, corpus, doc_term){
## Required packages
library(topicmodels)
library(dplyr)
library(stringi)
library(tm)
library(LDAvis)
## Find required quantities
phi <- posterior(fitted)$terms %>% as.matrix
theta <- posterior(fitted)$topics %>% as.matrix
vocab <- colnames(phi)
doc_length <- vector()
for (i in 1:length(corpus)) {
temp <- paste(corpus[[i]]$content, collapse = ' ')
doc_length <- c(doc_length, stri_count(temp, regex = '\\S+'))
}
print(doc_length)
temp_frequency <- inspect(doc_term)
freq_matrix <- data.frame(ST = colnames(temp_frequency),
Freq = colSums(temp_frequency))
rm(temp_frequency)
## Convert to json
json_lda <- LDAvis::createJSON(phi = phi, theta = theta,
vocab = vocab,
doc.length = doc_length,
term.frequency = freq_matrix$Freq)
return(json_lda)
}
phJSON <- topicmodels_json_ldavis(phAll.lda, phAll, phAll.dtm)
up
u
dim(phi)
dim(theta)
doc.length
length(doc.length)
dim(phi)
dim(theta)
q
phJSON <- topicmodels_json_ldavis(phAll.lda, phAll.nonZero, phAll.dtm)
phJSON <- topicmodels_json_ldavis(phAll.lda, phAll.nonZero, phAll.dtm)
topicmodels_json_ldavis <- function(fitted, corpus, doc_term){
## Required packages
library(topicmodels)
library(dplyr)
library(stringi)
library(tm)
library(LDAvis)
## Find required quantities
phi <- posterior(fitted)$terms %>% as.matrix
theta <- posterior(fitted)$topics %>% as.matrix
vocab <- colnames(phi)
doc_length <- vector()
for (i in 1:length(corpus)) {
temp <- paste(corpus[[i]]$content, collapse = ' ')
doc_length <- c(doc_length, stri_count(temp, regex = '\\S+'))
}
temp_frequency <- inspect(doc_term)
freq_matrix <- data.frame(ST = colnames(temp_frequency),
Freq = colSums(temp_frequency))
rm(temp_frequency)
## Convert to json
json_lda <- LDAvis::createJSON(phi = phi, theta = theta,
vocab = vocab,
doc.length = doc_length,
term.frequency = freq_matrix$Freq)
return(json_lda)
}
phJSON <- topicmodels_json_ldavis(phAll.lda, phAll.nonZero, phAll.dtm)
topicmodels_json_ldavis <- function(fitted, corpus, doc_term){
## Required packages
library(topicmodels)
library(dplyr)
library(stringi)
library(tm)
library(LDAvis)
## Find required quantities
phi <- posterior(fitted)$terms %>% as.matrix
theta <- posterior(fitted)$topics %>% as.matrix
vocab <- colnames(phi)
doc_length <- vector()
for (i in 1:length(corpus)) {
temp <- paste(corpus[[i]]$content, collapse = ' ')
doc_length <- c(doc_length, stri_count(temp, regex = '\\S+'))
}
temp_frequency <- inspect(doc_term)
freq_matrix <- data.frame(ST = colnames(temp_frequency),
Freq = colSums(temp_frequency))
rm(temp_frequency)
## Convert to json
json_lda <- LDAvis::createJSON(phi = phi, theta = theta,
vocab = vocab,
doc.length = doc_length,
term.frequency = freq_matrix$Freq)
return(json_lda)
}
phJSON <- topicmodels_json_ldavis(phAll.lda, phAll.nonZero, phAll.dtm)
objects(phAll.lda)
phAll.lda
laJSON <- topicmodels_json_ldavis(laAll.lda, laAll, laAll.dtm)
lenfth(phAll)
length(phAll)
dim(posterior(phAll.lda)$topics)
## Convert to document-term matrices
# Convert the "all" dtm's
phAll.dtm <- as.DocumentTermMatrix(phAll.tdm)
laAll.dtm <- as.DocumentTermMatrix(laAll.tdm)
## Identify first 5 topics
phAll.lda <- LDA(phAll.dtm, control = list(seed = 720), k = 5)
laAll.lda <- LDA(laAll.dtm, control = list(seed = 370), k = 5)
## Extract the first 5 terms of each topic
(phAll.term <- terms(phAll.lda, k = 5))
(laAll.term <- terms(laAll.lda, k = 5))
phAll.inds <- which(apply(phAll.dtm, 1, sum) > 0)
phAll.dtm <- phAll.dtm[phAll.inds, ]
laAll.inds <- which(apply(laAll.dtm, 1, sum) > 0)
laAll.dtm <- laAll.dtm[laAll.inds, ]
## Identify first 5 topics
phAll.lda <- LDA(phAll.dtm, control = list(seed = 720), k = 5)
laAll.lda <- LDA(laAll.dtm, control = list(seed = 370), k = 5)
(phAll.term <- terms(phAll.lda, k = 5))
(laAll.term <- terms(laAll.lda, k = 5))
phJSON <- topicmodels_json_ldavis(phAll.lda, phAll, phAll.dtm)
phAll.tdm <- TermDocumentMatrix(phAll, control = list(wordLengths = c(1, Inf)))
laAll.tdm <- TermDocumentMatrix(laAll, control = list(wordLengths = c(1, Inf)))
phAll.dtm <- as.DocumentTermMatrix(phAll.tdm)
laAll.dtm <- as.DocumentTermMatrix(laAll.tdm)
phAll.lda <- LDA(phAll.dtm, control = list(seed = 720), k = 5)
laAll.lda <- LDA(laAll.dtm, control = list(seed = 370), k = 5)
# Remove the zero entries
phAll.inds <- which(apply(phAll.dtm, 1, sum) > 0)
phAll.dtm <- phAll.dtm[phAll.inds, ]
laAll.inds <- which(apply(laAll.dtm, 1, sum) > 0)
laAll.dtm <- laAll.dtm[laAll.inds, ]
# Convert the dtm's grouped by hour
## Identify first 5 topics
phAll.lda <- LDA(phAll.dtm, control = list(seed = 720), k = 5)
laAll.lda <- LDA(laAll.dtm, control = list(seed = 370), k = 5)
phAll.inds
length(phAll.inds)
phJSON <- topicmodels_json_ldavis(phAll.lda, phAll[phAll.inds, ], phAll.dtm)
objects(phAll)
dim(phAll)$content
dim(phAll$content)
length(phAll$content)
class(phAll$content)
class(phAll$dmeta)
class(phAll$meta)
phAll$meta
phAll$dmeta
phAll.lda
objects(phAll.lda)
phAll.nz.Cor <- Corpus(phAll)
phAll.nz.Cor <- Corpus(VectorSource(phAll))
laAll.nz.Cor <- Corpus(VectorSource(laAll))
phJSON <- topicmodels_json_ldavis(phAll.lda, phAll.nz.Cor, phAll.dtm)
dim(phAll.dtm)
length(phAll.nz.Cor)
length(laAll.nz.Cor)
phAll.nz.Cor
phAll
phAll.nz.Cor <- Corpus(VectorSource(phAll$content))
laAll.nz.Cor <- Corpus(VectorSource(laAll$content))
phAll.nz.Cor
phJSON <- topicmodels_json_ldavis(phAll.lda, phAll.nz.Cor, phAll.dtm)
laJSON <- topicmodels_json_ldavis(laAll.lda, laAll.nz.Cor, laAll.dtm)
length(phAll.nz.Cor)
phAll.nz.Cor <- Corpus(VectorSource(phAll$content[phAll.inds]))
phJSON <- topicmodels_json_ldavis(phAll.lda, phAll.nz.Cor, phAll.dtm)
laAll.nz.Cor <- Corpus(VectorSource(laAll$content[laAll.inds]))
laJSON <- topicmodels_json_ldavis(laAll.lda, laAll.nz.Cor, laAll.dtm)
dim(inspect(phAll.dtm))
publish(user = "mjcho", repo = "CyberTrustMini")
summary(lm(score~category, laTopicsDF))
names(laTopicsDF)
summary(lm(score~category, dfPhone))
names(dfPhone)
summary(lm(meanScore ~ category, dfPhone))
levels(dfPhone$category)
table(dfPhone$category)
summary(lm(meanScore ~ category, subset(dfPhone, category != "")))
summary(lm(meanScore ~ category, subset(dfLaptop, category != "")))
